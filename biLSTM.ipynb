{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleased-forth",
   "metadata": {
    "id": "extra-seattle"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sorted-cable",
   "metadata": {
    "id": "married-client"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, Bidirectional, TimeDistributed, InputLayer\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, Input, concatenate, SpatialDropout1D, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"filtered_and_field_1.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-special",
   "metadata": {
    "id": "nonprofit-webcam"
   },
   "outputs": [],
   "source": [
    "target = [column for column in df.columns if \"field_\" in column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_abstract\"], df[target],\n",
    "                                                   train_size=0.4, test_size=0.1,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-remainder",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "destroyed-championship",
    "outputId": "9cab0e92-29c4-4c0e-90bf-48b96c6af771"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-chest",
   "metadata": {
    "id": "nearby-protest",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for sent in X_train:\n",
    "    sent = [word.lower() for word in sent.split()]\n",
    "    vocab.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unknown-publication",
   "metadata": {
    "id": "delayed-girlfriend"
   },
   "outputs": [],
   "source": [
    "filtered_vocab = {word for word in vocab if vocab[word] > 5}\n",
    "\n",
    "word2id = {word: i + 2 for i, word in enumerate(filtered_vocab)}\n",
    "word2id['pad'] = 0\n",
    "word2id['unk'] = 1  \n",
    "\n",
    "id2word = {i: word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accepted-treasury",
   "metadata": {
    "id": "loaded-reynolds"
   },
   "outputs": [],
   "source": [
    "def data2ints(data, smth2id):\n",
    "    int_data = []\n",
    "    for seq in data:\n",
    "        int_seq = []\n",
    "        for i in seq:\n",
    "            int_seq.append(smth2id.get(i.lower(), 1))\n",
    "  \n",
    "        int_data.append(int_seq)\n",
    "    return int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "whole-emphasis",
   "metadata": {
    "id": "reverse-seven"
   },
   "outputs": [],
   "source": [
    "X_train_ids, X_test_ids = data2ints(X_train, word2id), data2ints(X_test, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alike-configuration",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "distant-cookie",
    "outputId": "8d5f9faa-9da8-45e4-a797-0d8dcb241406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_max_len = max(len(x) for x in X_train_ids)\n",
    "\n",
    "sent_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "derived-stomach",
   "metadata": {
    "id": "enhanced-lawsuit"
   },
   "outputs": [],
   "source": [
    "X_train_pad, X_test_pad = pad_sequences(X_train_ids, maxlen=sent_max_len, padding='post'), pad_sequences(X_test_ids, maxlen=sent_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "careful-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = y_train[\"field_Biology\"]\n",
    "#y_test = y_test[\"field_Biology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "portuguese-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_replaced = [elem if elem == 1 else 0 for elem in y_test[\"field_Biology\"]]\n",
    "y_train_replaced = [elem if elem == 1 else 0 for elem in y_train[\"field_Biology\"]]\n",
    "\n",
    "y_train_cat = to_categorical(y_train_replaced, num_classes=2)\n",
    "y_test_cat = to_categorical(y_test_replaced, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "following-product",
   "metadata": {
    "id": "racial-distributor"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-upper",
   "metadata": {
    "id": "acquired-sharp"
   },
   "source": [
    "# Архитектура 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-affairs",
   "metadata": {
    "id": "narrative-smooth"
   },
   "source": [
    "модель берет слова, пропускает их через Embedding слой. По эмбеддингам проходит biLSTM, на выходе линейный слой и выходной слой.\n",
    "\n",
    "Embedding слой обучается внутри модели -- 1 балл\n",
    "\n",
    "подгружаются обученные эмбеддинги для русского языка ** -- 1 балл\n",
    "\n",
    "fasttext эмбеддинги обучаются на всем корпусе с нуля *** -- 2 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "widespread-switch",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "perceived-springer",
    "outputId": "51063883-f290-488f-b4ce-c2f7e6c06a96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((847375, 2999), (847375, 2), (211844, 2999), (211844, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train_cat.shape, X_test.shape, y_test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dedicated-allowance",
   "metadata": {
    "id": "accredited-opportunity"
   },
   "outputs": [],
   "source": [
    "word_in = Input(shape=(sent_max_len))\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len, mask_zero=True)(word_in)\n",
    "lstm = Bidirectional(LSTM(units=128))(emb_word)\n",
    "out = Dense(2, activation=\"softmax\")(lstm)\n",
    "\n",
    "model = Model(inputs=word_in, outputs=out)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "native-chassis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhLvykWX0mqs",
    "outputId": "aa430799-3fb7-42ed-931a-8cd9ca003633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2999)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2999, 20)          560840    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               152576    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 713,930\n",
      "Trainable params: 713,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "several-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "capital-boutique",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVeNEkCj20en",
    "outputId": "89b85826-f2e1-4489-b2ca-1957149a0569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "133/133 [==============================] - 475s 4s/step - loss: 0.6281 - precision_1: 0.6832 - recall_1: 0.6832 - accuracy: 0.0000e+00 - val_loss: 0.5947 - val_precision_1: 0.6882 - val_recall_1: 0.6882 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "133/133 [==============================] - 473s 4s/step - loss: 0.5953 - precision_1: 0.6849 - recall_1: 0.6849 - accuracy: 0.0000e+00 - val_loss: 0.5915 - val_precision_1: 0.6889 - val_recall_1: 0.6889 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe01cc88400>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), batch_size=128, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-wilson",
   "metadata": {
    "id": "9Wtpi_Vcu5nj"
   },
   "source": [
    "С accuracy проблема: модель предсказывает числа типа 9.7562476e-1, а сравнивает с 0 и 1. Давайте округлим и пересчитаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dressed-hypothesis",
   "metadata": {
    "id": "zmtq8jPGszTM"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test[:1000])  # полностью предсказывает долго\r\n",
    "\r\n",
    "rounded_pred = []\r\n",
    "for pair in pred:\r\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "informal-pleasure",
   "metadata": {
    "id": "4nN9HEj2bmA5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hourly-japan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FejcGSfcVvW",
    "outputId": "943608d7-72a2-4167-a1fd-cb6a7072b97b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5016425107474342\n",
      "Recall: 0.589859437751004\n",
      "Accuracy: 0.679\n"
     ]
    }
   ],
   "source": [
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\r\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\r\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\r\n",
    "\r\n",
    "print(f\"Precision: {prec}\")\r\n",
    "print(f\"Recall: {rec}\")\r\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-table",
   "metadata": {
    "id": "Ew_FFpOm3zCe"
   },
   "source": [
    "# Архитектура 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "inner-rental",
   "metadata": {
    "id": "A8CXnl3532jp"
   },
   "outputs": [],
   "source": [
    "# изменим размерность эмбеддингов и лстм, добавим дропаут\r\n",
    "\r\n",
    "word_in = Input(shape=(sent_max_len))\r\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=50, input_length=sent_max_len, mask_zero=True)(word_in)\r\n",
    "lstm = Bidirectional(LSTM(units=256, recurrent_dropout=0.15))(emb_word)\r\n",
    "out = Dense(2, activation=\"softmax\")(lstm)\r\n",
    "\r\n",
    "model = Model(inputs=word_in, outputs=out)\r\n",
    "\r\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\r\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "understood-saying",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypYmK7sq4j2m",
    "outputId": "882b696c-b15a-469a-9224-8ba964c8b728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 2999)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 2999, 50)          1402100   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 512)               628736    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 2,031,862\n",
      "Trainable params: 2,031,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "expired-lesson",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHvD7EgC41vl",
    "outputId": "853903b6-9fb7-44c9-e774-ae6c4144bf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "133/133 [==============================] - 1745s 13s/step - loss: 0.6656 - precision_1: 0.6725 - recall_1: 0.6675 - accuracy: 0.0000e+00 - val_loss: 0.5999 - val_precision_1: 0.6887 - val_recall_1: 0.6887 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "133/133 [==============================] - 1748s 13s/step - loss: 0.5987 - precision_1: 0.6814 - recall_1: 0.6814 - accuracy: 0.0000e+00 - val_loss: 0.5902 - val_precision_1: 0.6892 - val_recall_1: 0.6892 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0413779a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), batch_size=128, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "round-screen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-EoRW41hzCw",
    "outputId": "56d30bfe-1076-405d-8158-53f963c370cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5048426538936222\n",
      "Recall: 0.6183428635497253\n",
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test[:1000])\r\n",
    "\r\n",
    "rounded_pred = []\r\n",
    "for pair in pred:\r\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\r\n",
    "\r\n",
    "\r\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\r\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\r\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\r\n",
    "\r\n",
    "print(f\"Precision: {prec}\")\r\n",
    "print(f\"Recall: {rec}\")\r\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-michigan",
   "metadata": {
    "id": "7bR606P_PwgK"
   },
   "source": [
    "# Архитектура 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "finite-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вернем размерности, оставим дропаут\n",
    "\n",
    "word_in = Input(shape=(sent_max_len))\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len, mask_zero=True)(word_in)\n",
    "lstm = Bidirectional(LSTM(units=128, recurrent_dropout=0.15))(emb_word)\n",
    "out = Dense(2, activation=\"softmax\")(lstm)\n",
    "\n",
    "model = Model(inputs=word_in, outputs=out)\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-correction",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KUYElX9P6pS",
    "outputId": "a18eb79d-ee45-4a03-a902-ab6790579a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055/6621 [===>..........................] - ETA: 6:41:04 - loss: 0.6208 - precision: 0.6867 - recall: 0.6867 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train_cat, validation_data=(X_test_pad, y_test_cat), batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_pad[:1000])\n",
    "\n",
    "rounded_pred = []\n",
    "for pair in pred:\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\n",
    "\n",
    "\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(rounded_pred, y_test_cat[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-differential",
   "metadata": {},
   "source": [
    "На биологии и половине данных:\n",
    "\n",
    "Precision: 0.83 среднее (0.94 и 0.72)\n",
    "Recall: 0.86 среднее (0.88 и 0.85)\n",
    "Accuracy: 0.87\n",
    "\n",
    "Для TF-IDF + Logreg было для класса 1 0.88 0.80 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-advancement",
   "metadata": {},
   "source": [
    "# Эмбеддинги fasttext с нуля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "timely-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_abstract\"], df[target],\n",
    "                                                   train_size=0.008, test_size=0.002,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "mechanical-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.concatenate([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "focused-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "ft = gensim.models.FastText(corpus, size=300, iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "forty-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_weights = np.array([ft.wv.__getitem__(id2word[id_]) for id_ in id2word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "suffering-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in = Input(shape=(sent_max_len))\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=300, trainable=False, weights=[ft_weights])(word_in)\n",
    "lstm = Bidirectional(LSTM(units=128, recurrent_dropout=0.15))(emb_word)\n",
    "out = Dense(2, activation=\"softmax\")(lstm)\n",
    "\n",
    "model = Model(inputs=word_in, outputs=out)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "worth-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 2999)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 2999, 300)         8412600   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               439296    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 8,852,410\n",
      "Trainable params: 439,810\n",
      "Non-trainable params: 8,412,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "religious-nelson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 775s 6s/step - loss: 0.6288 - precision_1: 0.6801 - recall_1: 0.6801 - accuracy: 0.0000e+00 - val_loss: 0.6160 - val_precision_1: 0.6887 - val_recall_1: 0.6887 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe003c70370>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = pad_sequences(X_train_ids, maxlen=sent_max_len, padding='post'), pad_sequences(X_test_ids, maxlen=sent_max_len, padding='post')\n",
    "\n",
    "model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "restricted-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 0.3395\n",
      "Accuracy: 0.679\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test[:1000])\n",
    "\n",
    "rounded_pred = []\n",
    "for pair in pred:\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\n",
    "\n",
    "\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\", zero_division=0)\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\", zero_division=0)\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-eleven",
   "metadata": {},
   "source": [
    "# Два входа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "abandoned-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 {'5', 'υ', '≃', 'в', '8', 'á', '’', '©', 'õ', '½', '∩', 'ù', 'с', 'å', 'm', 'º', 'μ', 'ℒ', 'р', '≡', 'ν', 'ℵ', 'l', '≫', 'é', '»', '̇', '∘', 'b', 'z', 'ü', 'ϕ', '∞', 'δ', '°', 'м', 'ū', '«', '≥', '∧', 'β', '—', 'o', 'ç', '𝔇', 'í', 'κ', 'g', '̈', '1', 'd', 'ℝ', '⊐', '\\x96', '𝔼', '§', '⊕', 'v', 'a', '7', '“', 'ƒ', 'γ', '♂', 'į', 'ω', 'y', 'и', 'α', 'à', 'ε', 'ń', '⋆', '∑', '⊙', 'i', 'ó', 'x', 's', 'ě', '–', 'ô', 'c', 'j', 'ú', 'ö', '±', 'n', '⋅', 'r', 'ρ', 'p', 'τ', 'q', 'λ', 'ā', '×', 'u', '…', 'ê', 'è', 'ã', '≳', '⊂', '·', 'ṁ', 'σ', '≠', '≈', '̊', '²', '•', 'η', 'f', '2', 'т', 'µ', '‖', 'ξ', 'ζ', 'ï', 't', '3', '∼', 'π', '≤', '∈', 'h', '‘', 'đ', 'â', '¼', '0', 'k', 'ñ', 'у', 'ℓ', '′', 'ä', 'ß', '®', '≦', 'ψ', '6', 'θ', '✓', '˙', '−', 'ḥ', 'e', '∪', 'ϵ', 'χ', '→', '”', 'ű', '4', '\\ue700', '€', 'φ', 'w', '9'}\n"
     ]
    }
   ],
   "source": [
    "chars = set([letter for word in filtered_vocab for letter in word])\n",
    "n_chars = len(chars)\n",
    "print(len(chars), chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "three-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2id[\"pad\"] = 0\n",
    "char2id[\"unk\"] = 1\n",
    "\n",
    "id2char = {i: char for char, i in char2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "meaning-chicken",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "максимальная длина слова: 28\n"
     ]
    }
   ],
   "source": [
    "char_max_len = max(len(x) for x in filtered_vocab)\n",
    "print(\"максимальная длина слова:\", char_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "sonic-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_abstract\"], df[target],\n",
    "                                                   train_size=0.008, test_size=0.002,\n",
    "                                                   random_state=42)\n",
    "\n",
    "X_train, X_test = pad_sequences(X_train_ids, maxlen=sent_max_len, padding='post'), pad_sequences(X_test_ids, maxlen=sent_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "approved-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_char(sentences):\n",
    "  X_char = []\n",
    "  for sentence in sentences:\n",
    "      sent_seq = []\n",
    "      for i in range(sent_max_len):\n",
    "          word_seq = []\n",
    "          for j in range(char_max_len):\n",
    "              try:\n",
    "                  word_seq.append(char2id[sentence[i][j].lower()])\n",
    "              except:\n",
    "                  word_seq.append(char2id[\"pad\"])\n",
    "          sent_seq.append(word_seq)\n",
    "      X_char.append(np.array(sent_seq))\n",
    "  return np.array(X_char)\n",
    "\n",
    "\n",
    "X_char_train, X_char_test = make_X_char(X_train), make_X_char(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bigger-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in = Input(shape=(sent_max_len))\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len, mask_zero=True)(word_in)\n",
    "\n",
    "char_in = Input(shape=(sent_max_len, char_max_len))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=len(char2id), output_dim=10, input_length=char_max_len))(char_in)\n",
    "char_enc = TimeDistributed(Conv1D(filters=12, kernel_size=3))(emb_char)\n",
    "char_flat = TimeDistributed(Flatten())(char_enc)\n",
    "\n",
    "x = concatenate([emb_word, char_flat])\n",
    "main_lstm = Bidirectional(LSTM(units=128,\n",
    "                               recurrent_dropout=0.15)\n",
    "                         )(x)\n",
    "out = Dense(2, activation=\"softmax\")(main_lstm)\n",
    "\n",
    "model = Model(inputs=[char_in, word_in], outputs=out)\n",
    "\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "opening-source",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 2999, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 2999, 28, 10) 1640        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 2999)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 2999, 26, 12) 372         time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 2999, 20)     560840      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 2999, 312)    0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2999, 332)    0           embedding_7[0][0]                \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 256)          472064      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            514         bidirectional_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,035,430\n",
      "Trainable params: 1,035,430\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "frank-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16947, 2999, 28), (16947, 2999), (16947, 2))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_char_train.shape, X_train.shape, y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "central-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1219s 9s/step - loss: 0.6219 - precision_1: 0.6841 - recall_1: 0.6841 - accuracy: 0.0000e+00 - val_loss: 0.6044 - val_precision_1: 0.6887 - val_recall_1: 0.6887 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe02602ee20>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_char_train, X_train], y_train_cat, validation_data=([X_char_test, X_test], y_test_cat), batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "incoming-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 0.3395\n",
      "Accuracy: 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grafd/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "pred = model.predict([X_char_test[:1000], X_test[:1000]])\n",
    "\n",
    "rounded_pred = []\n",
    "for pair in pred:\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\n",
    "\n",
    "\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "tender-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418/1418 [==============================] - 937s 660ms/step - loss: 0.6109 - precision: 0.6475 - recall: 0.6475 - accuracy: 0.0000e+00 - val_loss: 0.6050 - val_precision: 0.6540 - val_recall: 0.6540 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbc69067580>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_char_train, X_train], y_train_cat, validation_data=([X_char_test, X_test], y_test_cat), batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "careful-brazil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6472903566457063\n",
      "Recall: 0.6686637717803551\n",
      "Accuracy: 0.648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "pred = model.predict([X_char_test[:1000], X_test[:1000]])\n",
    "\n",
    "rounded_pred = []\n",
    "for pair in pred:\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\n",
    "\n",
    "\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "artistic-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>subject</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>filtered_subject</th>\n",
       "      <th>all_fields</th>\n",
       "      <th>field_Art</th>\n",
       "      <th>field_Biology</th>\n",
       "      <th>field_Business</th>\n",
       "      <th>field_Chemistry</th>\n",
       "      <th>field_Geology</th>\n",
       "      <th>field_Humanities</th>\n",
       "      <th>field_Math</th>\n",
       "      <th>field_Medicine</th>\n",
       "      <th>field_Physics</th>\n",
       "      <th>field_Psychology</th>\n",
       "      <th>field_Social</th>\n",
       "      <th>field_Tech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1163/1568525043083505</td>\n",
       "      <td>aristotle fr. 44 rose: midas and silenus</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Classics, Linguistics and Language, Archaeolo...</td>\n",
       "      <td>abstract scholars have identified two supposed...</td>\n",
       "      <td>[Archaeology, Classics, History, Language and ...</td>\n",
       "      <td>[Humanities, Humanities, Humanities, Humanitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1163/1568525043083532</td>\n",
       "      <td>loca loquuntur. lucretius' explanation of the ...</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Classics, Linguistics and Language, Archaeolo...</td>\n",
       "      <td>abstract a discussion of the second part of lu...</td>\n",
       "      <td>[Archaeology, Classics, History, Language and ...</td>\n",
       "      <td>[Humanities, Humanities, Humanities, Humanitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1163/1568525043083541</td>\n",
       "      <td>poverty and demography: the case of the gracch...</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Classics, Linguistics and Language, Archaeolo...</td>\n",
       "      <td>abstract according to many ancient historians ...</td>\n",
       "      <td>[Archaeology, Classics, History, Language and ...</td>\n",
       "      <td>[Humanities, Humanities, Humanities, Humanitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1163/1568525043083514</td>\n",
       "      <td>old persian in athens revisited (ar. ach. 100)</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Classics, Linguistics and Language, Archaeolo...</td>\n",
       "      <td>abstract the old persian line in aristophanes ...</td>\n",
       "      <td>[Archaeology, Classics, History, Language and ...</td>\n",
       "      <td>[Humanities, Humanities, Humanities, Humanitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1163/1568527053083412</td>\n",
       "      <td>religion and violence: what can sociology offer?</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Religious studies, History]</td>\n",
       "      <td>abstract this essay presents a sketch of a soc...</td>\n",
       "      <td>[History, Religious studies]</td>\n",
       "      <td>[Humanities, Humanities]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DOI  \\\n",
       "0  10.1163/1568525043083505   \n",
       "1  10.1163/1568525043083532   \n",
       "2  10.1163/1568525043083541   \n",
       "3  10.1163/1568525043083514   \n",
       "4  10.1163/1568527053083412   \n",
       "\n",
       "                                               title  \\\n",
       "0           aristotle fr. 44 rose: midas and silenus   \n",
       "1  loca loquuntur. lucretius' explanation of the ...   \n",
       "2  poverty and demography: the case of the gracch...   \n",
       "3     old persian in athens revisited (ar. ach. 100)   \n",
       "4   religion and violence: what can sociology offer?   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "1  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "2  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "3  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "4  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  [Classics, Linguistics and Language, Archaeolo...   \n",
       "1  [Classics, Linguistics and Language, Archaeolo...   \n",
       "2  [Classics, Linguistics and Language, Archaeolo...   \n",
       "3  [Classics, Linguistics and Language, Archaeolo...   \n",
       "4                       [Religious studies, History]   \n",
       "\n",
       "                                    cleaned_abstract  \\\n",
       "0  abstract scholars have identified two supposed...   \n",
       "1  abstract a discussion of the second part of lu...   \n",
       "2  abstract according to many ancient historians ...   \n",
       "3  abstract the old persian line in aristophanes ...   \n",
       "4  abstract this essay presents a sketch of a soc...   \n",
       "\n",
       "                                    filtered_subject  \\\n",
       "0  [Archaeology, Classics, History, Language and ...   \n",
       "1  [Archaeology, Classics, History, Language and ...   \n",
       "2  [Archaeology, Classics, History, Language and ...   \n",
       "3  [Archaeology, Classics, History, Language and ...   \n",
       "4                       [History, Religious studies]   \n",
       "\n",
       "                                          all_fields  field_Art  \\\n",
       "0  [Humanities, Humanities, Humanities, Humanitie...          0   \n",
       "1  [Humanities, Humanities, Humanities, Humanitie...          0   \n",
       "2  [Humanities, Humanities, Humanities, Humanitie...          0   \n",
       "3  [Humanities, Humanities, Humanities, Humanitie...          0   \n",
       "4                           [Humanities, Humanities]          0   \n",
       "\n",
       "   field_Biology  field_Business  field_Chemistry  field_Geology  \\\n",
       "0              0               0                0              0   \n",
       "1              0               0                0              0   \n",
       "2              0               0                0              0   \n",
       "3              0               0                0              0   \n",
       "4              0               0                0              0   \n",
       "\n",
       "   field_Humanities  field_Math  field_Medicine  field_Physics  \\\n",
       "0                 1           0               0              0   \n",
       "1                 1           0               0              0   \n",
       "2                 1           0               0              0   \n",
       "3                 1           0               0              0   \n",
       "4                 1           0               0              0   \n",
       "\n",
       "   field_Psychology  field_Social  field_Tech  \n",
       "0                 0             0           0  \n",
       "1                 0             0           0  \n",
       "2                 0             0           0  \n",
       "3                 0             0           0  \n",
       "4                 0             0           0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-diary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw6_twits.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
