{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleased-forth",
   "metadata": {
    "id": "extra-seattle"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sorted-cable",
   "metadata": {
    "id": "married-client"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, Bidirectional, TimeDistributed, InputLayer\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, Input, concatenate, SpatialDropout1D, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"filtered_and_field_1.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-special",
   "metadata": {
    "id": "nonprofit-webcam"
   },
   "outputs": [],
   "source": [
    "target = [column for column in df.columns if \"field_\" in column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_abstract\"], df[target],\n",
    "                                                   train_size=0.4, test_size=0.1,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-remainder",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "destroyed-championship",
    "outputId": "9cab0e92-29c4-4c0e-90bf-48b96c6af771"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-chest",
   "metadata": {
    "id": "nearby-protest",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for sent in X_train:\n",
    "    sent = [word.lower() for word in sent.split()]\n",
    "    vocab.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unknown-publication",
   "metadata": {
    "id": "delayed-girlfriend"
   },
   "outputs": [],
   "source": [
    "filtered_vocab = {word for word in vocab if vocab[word] > 5}\n",
    "\n",
    "word2id = {word: i + 2 for i, word in enumerate(filtered_vocab)}\n",
    "word2id['pad'] = 0\n",
    "word2id['unk'] = 1  \n",
    "\n",
    "id2word = {i: word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accepted-treasury",
   "metadata": {
    "id": "loaded-reynolds"
   },
   "outputs": [],
   "source": [
    "def data2ints(data, smth2id):\n",
    "    int_data = []\n",
    "    for seq in data:\n",
    "        int_seq = []\n",
    "        for i in seq:\n",
    "            int_seq.append(smth2id.get(i.lower(), 1))\n",
    "  \n",
    "        int_data.append(int_seq)\n",
    "    return int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "whole-emphasis",
   "metadata": {
    "id": "reverse-seven"
   },
   "outputs": [],
   "source": [
    "X_train_ids, X_test_ids = data2ints(X_train, word2id), data2ints(X_test, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alike-configuration",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "distant-cookie",
    "outputId": "8d5f9faa-9da8-45e4-a797-0d8dcb241406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_max_len = max(len(x) for x in X_train_ids)\n",
    "\n",
    "sent_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "derived-stomach",
   "metadata": {
    "id": "enhanced-lawsuit"
   },
   "outputs": [],
   "source": [
    "X_train_pad, X_test_pad = pad_sequences(X_train_ids, maxlen=sent_max_len, padding='post'), pad_sequences(X_test_ids, maxlen=sent_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "careful-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = y_train[\"field_Biology\"]\n",
    "#y_test = y_test[\"field_Biology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "portuguese-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_replaced = [elem if elem == 1 else 0 for elem in y_test[\"field_Biology\"]]\n",
    "y_train_replaced = [elem if elem == 1 else 0 for elem in y_train[\"field_Biology\"]]\n",
    "\n",
    "y_train_cat = to_categorical(y_train_replaced, num_classes=2)\n",
    "y_test_cat = to_categorical(y_test_replaced, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "following-product",
   "metadata": {
    "id": "racial-distributor"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-upper",
   "metadata": {
    "id": "acquired-sharp"
   },
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-affairs",
   "metadata": {
    "id": "narrative-smooth"
   },
   "source": [
    "–º–æ–¥–µ–ª—å –±–µ—Ä–µ—Ç —Å–ª–æ–≤–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∏—Ö —á–µ—Ä–µ–∑ Embedding —Å–ª–æ–π. –ü–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –ø—Ä–æ—Ö–æ–¥–∏—Ç biLSTM, –Ω–∞ –≤—ã—Ö–æ–¥–µ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –∏ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π.\n",
    "\n",
    "Embedding —Å–ª–æ–π –æ–±—É—á–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –º–æ–¥–µ–ª–∏ -- 1 –±–∞–ª–ª\n",
    "\n",
    "–ø–æ–¥–≥—Ä—É–∂–∞—é—Ç—Å—è –æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ ** -- 1 –±–∞–ª–ª\n",
    "\n",
    "fasttext —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ–±—É—á–∞—é—Ç—Å—è –Ω–∞ –≤—Å–µ–º –∫–æ—Ä–ø—É—Å–µ —Å –Ω—É–ª—è *** -- 2 –±–∞–ª–ª–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "widespread-switch",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "perceived-springer",
    "outputId": "51063883-f290-488f-b4ce-c2f7e6c06a96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((847375, 2999), (847375, 2), (211844, 2999), (211844, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train_cat.shape, X_test.shape, y_test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dedicated-allowance",
   "metadata": {
    "id": "accredited-opportunity"
   },
   "outputs": [],
   "source": [
    "word_in = Input(shape=(sent_max_len))\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len, mask_zero=True)(word_in)\n",
    "lstm = Bidirectional(LSTM(units=128))(emb_word)\n",
    "out = Dense(2, activation=\"softmax\")(lstm)\n",
    "\n",
    "model = Model(inputs=word_in, outputs=out)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "native-chassis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhLvykWX0mqs",
    "outputId": "aa430799-3fb7-42ed-931a-8cd9ca003633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2999)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2999, 20)          560840    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               152576    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 713,930\n",
      "Trainable params: 713,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "several-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "capital-boutique",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVeNEkCj20en",
    "outputId": "89b85826-f2e1-4489-b2ca-1957149a0569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "133/133 [==============================] - 475s 4s/step - loss: 0.6281 - precision_1: 0.6832 - recall_1: 0.6832 - accuracy: 0.0000e+00 - val_loss: 0.5947 - val_precision_1: 0.6882 - val_recall_1: 0.6882 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "133/133 [==============================] - 473s 4s/step - loss: 0.5953 - precision_1: 0.6849 - recall_1: 0.6849 - accuracy: 0.0000e+00 - val_loss: 0.5915 - val_precision_1: 0.6889 - val_recall_1: 0.6889 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe01cc88400>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), batch_size=128, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-wilson",
   "metadata": {
    "id": "9Wtpi_Vcu5nj"
   },
   "source": [
    "–° accuracy –ø—Ä–æ–±–ª–µ–º–∞: –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —á–∏—Å–ª–∞ —Ç–∏–ø–∞ 9.7562476e-1, –∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å 0 –∏ 1. –î–∞–≤–∞–π—Ç–µ –æ–∫—Ä—É–≥–ª–∏–º –∏ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dressed-hypothesis",
   "metadata": {
    "id": "zmtq8jPGszTM"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test[:1000])  # –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ–ª–≥–æ\r\n",
    "\r\n",
    "rounded_pred = []\r\n",
    "for pair in pred:\r\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "informal-pleasure",
   "metadata": {
    "id": "4nN9HEj2bmA5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hourly-japan",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FejcGSfcVvW",
    "outputId": "943608d7-72a2-4167-a1fd-cb6a7072b97b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5016425107474342\n",
      "Recall: 0.589859437751004\n",
      "Accuracy: 0.679\n"
     ]
    }
   ],
   "source": [
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\r\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\r\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\r\n",
    "\r\n",
    "print(f\"Precision: {prec}\")\r\n",
    "print(f\"Recall: {rec}\")\r\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-table",
   "metadata": {
    "id": "Ew_FFpOm3zCe"
   },
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "inner-rental",
   "metadata": {
    "id": "A8CXnl3532jp"
   },
   "outputs": [],
   "source": [
    "# –∏–∑–º–µ–Ω–∏–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –ª—Å—Ç–º, –¥–æ–±–∞–≤–∏–º –¥—Ä–æ–ø–∞—É—Ç\r\n",
    "\r\n",
    "word_in = Input(shape=(sent_max_len))\r\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=50, input_length=sent_max_len, mask_zero=True)(word_in)\r\n",
    "lstm = Bidirectional(LSTM(units=256, recurrent_dropout=0.15))(emb_word)\r\n",
    "out = Dense(2, activation=\"softmax\")(lstm)\r\n",
    "\r\n",
    "model = Model(inputs=word_in, outputs=out)\r\n",
    "\r\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\r\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "understood-saying",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypYmK7sq4j2m",
    "outputId": "882b696c-b15a-469a-9224-8ba964c8b728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 2999)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 2999, 50)          1402100   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 512)               628736    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 2,031,862\n",
      "Trainable params: 2,031,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "expired-lesson",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHvD7EgC41vl",
    "outputId": "853903b6-9fb7-44c9-e774-ae6c4144bf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "133/133 [==============================] - 1745s 13s/step - loss: 0.6656 - precision_1: 0.6725 - recall_1: 0.6675 - accuracy: 0.0000e+00 - val_loss: 0.5999 - val_precision_1: 0.6887 - val_recall_1: 0.6887 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "133/133 [==============================] - 1748s 13s/step - loss: 0.5987 - precision_1: 0.6814 - recall_1: 0.6814 - accuracy: 0.0000e+00 - val_loss: 0.5902 - val_precision_1: 0.6892 - val_recall_1: 0.6892 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0413779a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), batch_size=128, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "round-screen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-EoRW41hzCw",
    "outputId": "56d30bfe-1076-405d-8158-53f963c370cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5048426538936222\n",
      "Recall: 0.6183428635497253\n",
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test[:1000])\r\n",
    "\r\n",
    "rounded_pred = []\r\n",
    "for pair in pred:\r\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\r\n",
    "\r\n",
    "\r\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\r\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\r\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\r\n",
    "\r\n",
    "print(f\"Precision: {prec}\")\r\n",
    "print(f\"Recall: {rec}\")\r\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-michigan",
   "metadata": {
    "id": "7bR606P_PwgK"
   },
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "finite-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤–µ—Ä–Ω–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, –æ—Å—Ç–∞–≤–∏–º –¥—Ä–æ–ø–∞—É—Ç\n",
    "\n",
    "word_in = Input(shape=(sent_max_len))\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len, mask_zero=True)(word_in)\n",
    "lstm = Bidirectional(LSTM(units=128, recurrent_dropout=0.15))(emb_word)\n",
    "out = Dense(2, activation=\"softmax\")(lstm)\n",
    "\n",
    "model = Model(inputs=word_in, outputs=out)\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-correction",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KUYElX9P6pS",
    "outputId": "a18eb79d-ee45-4a03-a902-ab6790579a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055/6621 [===>..........................] - ETA: 6:41:04 - loss: 0.6208 - precision: 0.6867 - recall: 0.6867 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train_cat, validation_data=(X_test_pad, y_test_cat), batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_pad[:1000])\n",
    "\n",
    "rounded_pred = []\n",
    "for pair in pred:\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\n",
    "\n",
    "\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(rounded_pred, y_test_cat[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-differential",
   "metadata": {},
   "source": [
    "–ù–∞ –±–∏–æ–ª–æ–≥–∏–∏ –∏ –ø–æ–ª–æ–≤–∏–Ω–µ –¥–∞–Ω–Ω—ã—Ö:\n",
    "\n",
    "Precision: 0.83 —Å—Ä–µ–¥–Ω–µ–µ (0.94 –∏ 0.72)\n",
    "Recall: 0.86 —Å—Ä–µ–¥–Ω–µ–µ (0.88 –∏ 0.85)\n",
    "Accuracy: 0.87\n",
    "\n",
    "–î–ª—è TF-IDF + Logreg –±—ã–ª–æ –¥–ª—è –∫–ª–∞—Å—Å–∞ 1 0.88 0.80 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-advancement",
   "metadata": {},
   "source": [
    "# –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ fasttext —Å –Ω—É–ª—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "timely-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_abstract\"], df[target],\n",
    "                                                   train_size=0.008, test_size=0.002,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "mechanical-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.concatenate([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "focused-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "ft = gensim.models.FastText(corpus, size=300, iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "forty-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_weights = np.array([ft.wv.__getitem__(id2word[id_]) for id_ in id2word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "suffering-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in = Input(shape=(sent_max_len))\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=300, trainable=False, weights=[ft_weights])(word_in)\n",
    "lstm = Bidirectional(LSTM(units=128, recurrent_dropout=0.15))(emb_word)\n",
    "out = Dense(2, activation=\"softmax\")(lstm)\n",
    "\n",
    "model = Model(inputs=word_in, outputs=out)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "worth-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 2999)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 2999, 300)         8412600   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               439296    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 8,852,410\n",
      "Trainable params: 439,810\n",
      "Non-trainable params: 8,412,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "religious-nelson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 775s 6s/step - loss: 0.6288 - precision_1: 0.6801 - recall_1: 0.6801 - accuracy: 0.0000e+00 - val_loss: 0.6160 - val_precision_1: 0.6887 - val_recall_1: 0.6887 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe003c70370>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = pad_sequences(X_train_ids, maxlen=sent_max_len, padding='post'), pad_sequences(X_test_ids, maxlen=sent_max_len, padding='post')\n",
    "\n",
    "model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "restricted-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 0.3395\n",
      "Accuracy: 0.679\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test[:1000])\n",
    "\n",
    "rounded_pred = []\n",
    "for pair in pred:\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\n",
    "\n",
    "\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\", zero_division=0)\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\", zero_division=0)\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-eleven",
   "metadata": {},
   "source": [
    "# –î–≤–∞ –≤—Ö–æ–¥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "abandoned-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 {'5', 'œÖ', '‚âÉ', '–≤', '8', '√°', '‚Äô', '¬©', '√µ', '¬Ω', '‚à©', '√π', '—Å', '√•', 'm', '¬∫', 'Œº', '‚Ñí', '—Ä', '‚â°', 'ŒΩ', '‚Ñµ', 'l', '‚â´', '√©', '¬ª', 'Ãá', '‚àò', 'b', 'z', '√º', 'œï', '‚àû', 'Œ¥', '¬∞', '–º', '≈´', '¬´', '‚â•', '‚àß', 'Œ≤', '‚Äî', 'o', '√ß', 'ùîá', '√≠', 'Œ∫', 'g', 'Ãà', '1', 'd', '‚Ñù', '‚äê', '\\x96', 'ùîº', '¬ß', '‚äï', 'v', 'a', '7', '‚Äú', '∆í', 'Œ≥', '‚ôÇ', 'ƒØ', 'œâ', 'y', '–∏', 'Œ±', '√†', 'Œµ', '≈Ñ', '‚ãÜ', '‚àë', '‚äô', 'i', '√≥', 'x', 's', 'ƒõ', '‚Äì', '√¥', 'c', 'j', '√∫', '√∂', '¬±', 'n', '‚ãÖ', 'r', 'œÅ', 'p', 'œÑ', 'q', 'Œª', 'ƒÅ', '√ó', 'u', '‚Ä¶', '√™', '√®', '√£', '‚â≥', '‚äÇ', '¬∑', '·πÅ', 'œÉ', '‚â†', '‚âà', 'Ãä', '¬≤', '‚Ä¢', 'Œ∑', 'f', '2', '—Ç', '¬µ', '‚Äñ', 'Œæ', 'Œ∂', '√Ø', 't', '3', '‚àº', 'œÄ', '‚â§', '‚àà', 'h', '‚Äò', 'ƒë', '√¢', '¬º', '0', 'k', '√±', '—É', '‚Ñì', '‚Ä≤', '√§', '√ü', '¬Æ', '‚â¶', 'œà', '6', 'Œ∏', '‚úì', 'Àô', '‚àí', '·∏•', 'e', '‚à™', 'œµ', 'œá', '‚Üí', '‚Äù', '≈±', '4', '\\ue700', '‚Ç¨', 'œÜ', 'w', '9'}\n"
     ]
    }
   ],
   "source": [
    "chars = set([letter for word in filtered_vocab for letter in word])\n",
    "n_chars = len(chars)\n",
    "print(len(chars), chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "three-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2id[\"pad\"] = 0\n",
    "char2id[\"unk\"] = 1\n",
    "\n",
    "id2char = {i: char for char, i in char2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "meaning-chicken",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞: 28\n"
     ]
    }
   ],
   "source": [
    "char_max_len = max(len(x) for x in filtered_vocab)\n",
    "print(\"–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞:\", char_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "sonic-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_abstract\"], df[target],\n",
    "                                                   train_size=0.008, test_size=0.002,\n",
    "                                                   random_state=42)\n",
    "\n",
    "X_train, X_test = pad_sequences(X_train_ids, maxlen=sent_max_len, padding='post'), pad_sequences(X_test_ids, maxlen=sent_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "approved-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_char(sentences):\n",
    "  X_char = []\n",
    "  for sentence in sentences:\n",
    "      sent_seq = []\n",
    "      for i in range(sent_max_len):\n",
    "          word_seq = []\n",
    "          for j in range(char_max_len):\n",
    "              try:\n",
    "                  word_seq.append(char2id[sentence[i][j].lower()])\n",
    "              except:\n",
    "                  word_seq.append(char2id[\"pad\"])\n",
    "          sent_seq.append(word_seq)\n",
    "      X_char.append(np.array(sent_seq))\n",
    "  return np.array(X_char)\n",
    "\n",
    "\n",
    "X_char_train, X_char_test = make_X_char(X_train), make_X_char(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bigger-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in = Input(shape=(sent_max_len))\n",
    "emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len, mask_zero=True)(word_in)\n",
    "\n",
    "char_in = Input(shape=(sent_max_len, char_max_len))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=len(char2id), output_dim=10, input_length=char_max_len))(char_in)\n",
    "char_enc = TimeDistributed(Conv1D(filters=12, kernel_size=3))(emb_char)\n",
    "char_flat = TimeDistributed(Flatten())(char_enc)\n",
    "\n",
    "x = concatenate([emb_word, char_flat])\n",
    "main_lstm = Bidirectional(LSTM(units=128,\n",
    "                               recurrent_dropout=0.15)\n",
    "                         )(x)\n",
    "out = Dense(2, activation=\"softmax\")(main_lstm)\n",
    "\n",
    "model = Model(inputs=[char_in, word_in], outputs=out)\n",
    "\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "opening-source",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 2999, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 2999, 28, 10) 1640        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 2999)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 2999, 26, 12) 372         time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 2999, 20)     560840      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 2999, 312)    0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2999, 332)    0           embedding_7[0][0]                \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 256)          472064      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            514         bidirectional_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,035,430\n",
      "Trainable params: 1,035,430\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "frank-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16947, 2999, 28), (16947, 2999), (16947, 2))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_char_train.shape, X_train.shape, y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "central-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1219s 9s/step - loss: 0.6219 - precision_1: 0.6841 - recall_1: 0.6841 - accuracy: 0.0000e+00 - val_loss: 0.6044 - val_precision_1: 0.6887 - val_recall_1: 0.6887 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe02602ee20>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_char_train, X_train], y_train_cat, validation_data=([X_char_test, X_test], y_test_cat), batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "incoming-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 0.3395\n",
      "Accuracy: 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grafd/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "pred = model.predict([X_char_test[:1000], X_test[:1000]])\n",
    "\n",
    "rounded_pred = []\n",
    "for pair in pred:\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\n",
    "\n",
    "\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "tender-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418/1418 [==============================] - 937s 660ms/step - loss: 0.6109 - precision: 0.6475 - recall: 0.6475 - accuracy: 0.0000e+00 - val_loss: 0.6050 - val_precision: 0.6540 - val_recall: 0.6540 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbc69067580>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_char_train, X_train], y_train_cat, validation_data=([X_char_test, X_test], y_test_cat), batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "careful-brazil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6472903566457063\n",
      "Recall: 0.6686637717803551\n",
      "Accuracy: 0.648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "pred = model.predict([X_char_test[:1000], X_test[:1000]])\n",
    "\n",
    "rounded_pred = []\n",
    "for pair in pred:\n",
    "  rounded_pred.append([round(pair[0]), round(pair[1])])\n",
    "\n",
    "\n",
    "prec = precision_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "rec = recall_score(rounded_pred, y_test_cat[:1000], average=\"macro\")\n",
    "acc = accuracy_score(rounded_pred, y_test_cat[:1000])\n",
    "\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "artistic-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>subject</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>filtered_subject</th>\n",
       "      <th>all_fields</th>\n",
       "      <th>field_Art</th>\n",
       "      <th>field_Biology</th>\n",
       "      <th>field_Business</th>\n",
       "      <th>field_Chemistry</th>\n",
       "      <th>field_Geology</th>\n",
       "      <th>field_Humanities</th>\n",
       "      <th>field_Math</th>\n",
       "      <th>field_Medicine</th>\n",
       "      <th>field_Physics</th>\n",
       "      <th>field_Psychology</th>\n",
       "      <th>field_Social</th>\n",
       "      <th>field_Tech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1163/1568525043083505</td>\n",
       "      <td>aristotle fr. 44 rose: midas and silenus</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Classics, Linguistics and Language, Archaeolo...</td>\n",
       "      <td>abstract scholars have identified two supposed...</td>\n",
       "      <td>[Archaeology, Classics, History, Language and ...</td>\n",
       "      <td>[Humanities, Humanities, Humanities, Humanitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1163/1568525043083532</td>\n",
       "      <td>loca loquuntur. lucretius' explanation of the ...</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Classics, Linguistics and Language, Archaeolo...</td>\n",
       "      <td>abstract a discussion of the second part of lu...</td>\n",
       "      <td>[Archaeology, Classics, History, Language and ...</td>\n",
       "      <td>[Humanities, Humanities, Humanities, Humanitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1163/1568525043083541</td>\n",
       "      <td>poverty and demography: the case of the gracch...</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Classics, Linguistics and Language, Archaeolo...</td>\n",
       "      <td>abstract according to many ancient historians ...</td>\n",
       "      <td>[Archaeology, Classics, History, Language and ...</td>\n",
       "      <td>[Humanities, Humanities, Humanities, Humanitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1163/1568525043083514</td>\n",
       "      <td>old persian in athens revisited (ar. ach. 100)</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Classics, Linguistics and Language, Archaeolo...</td>\n",
       "      <td>abstract the old persian line in aristophanes ...</td>\n",
       "      <td>[Archaeology, Classics, History, Language and ...</td>\n",
       "      <td>[Humanities, Humanities, Humanities, Humanitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1163/1568527053083412</td>\n",
       "      <td>religion and violence: what can sociology offer?</td>\n",
       "      <td>&lt;jats:sec&gt;&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;ja...</td>\n",
       "      <td>[Religious studies, History]</td>\n",
       "      <td>abstract this essay presents a sketch of a soc...</td>\n",
       "      <td>[History, Religious studies]</td>\n",
       "      <td>[Humanities, Humanities]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DOI  \\\n",
       "0  10.1163/1568525043083505   \n",
       "1  10.1163/1568525043083532   \n",
       "2  10.1163/1568525043083541   \n",
       "3  10.1163/1568525043083514   \n",
       "4  10.1163/1568527053083412   \n",
       "\n",
       "                                               title  \\\n",
       "0           aristotle fr. 44 rose: midas and silenus   \n",
       "1  loca loquuntur. lucretius' explanation of the ...   \n",
       "2  poverty and demography: the case of the gracch...   \n",
       "3     old persian in athens revisited (ar. ach. 100)   \n",
       "4   religion and violence: what can sociology offer?   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "1  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "2  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "3  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "4  <jats:sec><jats:title>Abstract</jats:title><ja...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  [Classics, Linguistics and Language, Archaeolo...   \n",
       "1  [Classics, Linguistics and Language, Archaeolo...   \n",
       "2  [Classics, Linguistics and Language, Archaeolo...   \n",
       "3  [Classics, Linguistics and Language, Archaeolo...   \n",
       "4                       [Religious studies, History]   \n",
       "\n",
       "                                    cleaned_abstract  \\\n",
       "0  abstract scholars have identified two supposed...   \n",
       "1  abstract a discussion of the second part of lu...   \n",
       "2  abstract according to many ancient historians ...   \n",
       "3  abstract the old persian line in aristophanes ...   \n",
       "4  abstract this essay presents a sketch of a soc...   \n",
       "\n",
       "                                    filtered_subject  \\\n",
       "0  [Archaeology, Classics, History, Language and ...   \n",
       "1  [Archaeology, Classics, History, Language and ...   \n",
       "2  [Archaeology, Classics, History, Language and ...   \n",
       "3  [Archaeology, Classics, History, Language and ...   \n",
       "4                       [History, Religious studies]   \n",
       "\n",
       "                                          all_fields  field_Art  \\\n",
       "0  [Humanities, Humanities, Humanities, Humanitie...          0   \n",
       "1  [Humanities, Humanities, Humanities, Humanitie...          0   \n",
       "2  [Humanities, Humanities, Humanities, Humanitie...          0   \n",
       "3  [Humanities, Humanities, Humanities, Humanitie...          0   \n",
       "4                           [Humanities, Humanities]          0   \n",
       "\n",
       "   field_Biology  field_Business  field_Chemistry  field_Geology  \\\n",
       "0              0               0                0              0   \n",
       "1              0               0                0              0   \n",
       "2              0               0                0              0   \n",
       "3              0               0                0              0   \n",
       "4              0               0                0              0   \n",
       "\n",
       "   field_Humanities  field_Math  field_Medicine  field_Physics  \\\n",
       "0                 1           0               0              0   \n",
       "1                 1           0               0              0   \n",
       "2                 1           0               0              0   \n",
       "3                 1           0               0              0   \n",
       "4                 1           0               0              0   \n",
       "\n",
       "   field_Psychology  field_Social  field_Tech  \n",
       "0                 0             0           0  \n",
       "1                 0             0           0  \n",
       "2                 0             0           0  \n",
       "3                 0             0           0  \n",
       "4                 0             0           0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-diary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw6_twits.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
